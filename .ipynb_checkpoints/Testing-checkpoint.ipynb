{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "from jieba import lcut, lcut_for_search\n",
    "\n",
    "dictionary = database.Dictionary()\n",
    "dictionary.create_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace in hanzi.py\n",
    "def split_hanzi(hanzi, grouped=True):\n",
    "    assert isinstance(hanzi, str)\n",
    "\n",
    "    if len(hanzi.split()) > 1:\n",
    "        separated = remove_empty(split('([ ,.，。])', hanzi))\n",
    "    else:\n",
    "        separated = list(cut(hanzi, cut_all=True))\n",
    "\n",
    "    if grouped:\n",
    "        return separated\n",
    "\n",
    "    return flatten(separated)\n",
    "\n",
    "def remove_empty(a):\n",
    "    return list(filter(lambda s: s.strip(), a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace in translate.py\n",
    "def translate_local(hanzi, lang):\n",
    "    \"\"\"Translate using local dictionary.\n",
    "\n",
    "    lang is one of 'en', 'fr', 'de', 'es'.\n",
    "    \"\"\"\n",
    "\n",
    "    defs = dictionary.get_definitions(hanzi, lang)\n",
    "\n",
    "    if not defs:\n",
    "        return ''\n",
    "    \n",
    "    res = '<br>'.join(['❖ %s[%s] %s' % (hanzi, pinyin, definition) for pinyin, definition, _, _ in defs])\n",
    "\n",
    "    return colorize_dict(res.replace('\\n', '; '))\n",
    "\n",
    "def translate_gloss(hanzi, lang):\n",
    "    '''Return a gloss for a sentence'''\n",
    "\n",
    "    words = split_hanzi(hanzi)\n",
    "    return '<hr>'.join(remove_empty([translate_local(word, lang) for word in words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❖ 这[zhe4] this; these; (commonly pr. [zhei4] before a classifier, esp. in Beijing)<br><hr>❖ 是[shi4] is; are; am; yes; to be<br>❖ 是[shi4] variant of 是[shi4]; (used in given names)<br>'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_gloss('这是一个', 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❖ 这[zhe4] this; these; (commonly pr. [zhei4] before a classifier, esp. in Beijing)\n",
      "❖ 是[shi4] is; are; am; yes; to be❖ 是[shi4] variant of 是[shi4]; (used in given names)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in split_hanzi('这是一个'):\n",
    "    print(translate_local(word, 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    this\\n<br>these\\n<br>(commonly pr. [zhei4] before a classifier, esp. in Beijing)\\n<br>        is\\n<br>are\\n<br>am\\n<br>yes\\n<br>to be\\n<br>    variant of 是[shi4]\\n<br>(used in given names)\\n<br>    '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'    '.join([translate_local(word, 'en') for word in split_hanzi('这是一个')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
